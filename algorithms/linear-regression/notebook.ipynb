{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 线性回归 (Linear Regression) - 动手实践\n",
    "\n",
    "在这个 Notebook 中，我们将从零实现线性回归算法，并通过代码加深理解。\n",
    "\n",
    "## 目标\n",
    "- 理解线性回归的数学原理\n",
    "- 实现梯度下降法求解\n",
    "- 对比闭式解与梯度下降\n",
    "- 在真实数据集上应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成示例数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子以保证可重复性\n",
    "np.random.seed(42)\n",
    "\n",
    "# 生成数据\n",
    "n_samples = 100\n",
    "true_slope = 2.5\n",
    "true_intercept = 1.0\n",
    "noise_level = 0.5\n",
    "\n",
    "X = 2 * np.random.rand(n_samples, 1)  # 特征: [0, 2]\n",
    "y = true_slope * X + true_intercept + noise_level * np.random.randn(n_samples, 1)\n",
    "\n",
    "print(f\"数据形状: X={X.shape}, y={y.shape}\")\n",
    "print(f\"真实参数: slope={true_slope}, intercept={true_intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 可视化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, alpha=0.6)\n",
    "plt.xlabel('X (特征)')\n",
    "plt.ylabel('y (目标)')\n",
    "plt.title('线性回归示例数据')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 方法一：闭式解 (Ordinary Least Squares)\n",
    "\n",
    "线性回归的闭式解公式：\n",
    "$$m = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2}, \\quad b = \\bar{y} - m\\bar{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_solution(X, y):\n",
    "    \"\"\"\n",
    "    计算线性回归的闭式解\n",
    "    \n",
    "    Args:\n",
    "        X: 特征矩阵 (n_samples, 1)\n",
    "        y: 目标值 (n_samples, 1)\n",
    "    \n",
    "    Returns:\n",
    "        slope, intercept: 回归系数\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    mean_x = np.mean(X)\n",
    "    mean_y = np.mean(y)\n",
    "    \n",
    "    # 计算斜率\n",
    "    numerator = np.sum((X - mean_x) * (y - mean_y))\n",
    "    denominator = np.sum((X - mean_x) ** 2)\n",
    "    slope = numerator[0] / denominator[0]\n",
    "    \n",
    "    # 计算截距\n",
    "    intercept = mean_y[0] - slope * mean_x[0]\n",
    "    \n",
    "    return slope, intercept\n",
    "\n",
    "# 使用闭式解求解\n",
    "slope_cf, intercept_cf = closed_form_solution(X, y)\n",
    "print(f\"闭式解结果: y = {slope_cf:.4f}x + {intercept_cf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 方法二：梯度下降法 (Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):\n",
    "    \"\"\"\n",
    "    使用梯度下降法求解线性回归\n",
    "    \n",
    "    Args:\n",
    "        X: 特征矩阵\n",
    "        y: 目标值\n",
    "        learning_rate: 学习率\n",
    "        n_iterations: 迭代次数\n",
    "    \n",
    "    Returns:\n",
    "        slope, intercept, history\n",
    "    \"\"\"\n",
    "    # 初始化参数\n",
    "    slope = 0.0\n",
    "    intercept = 0.0\n",
    "    n = len(X)\n",
    "    \n",
    "    # 存储历史用于可视化\n",
    "    history = {'slope': [], 'intercept': [], 'loss': []}\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # 前向传播：计算预测值\n",
    "        y_pred = slope * X.flatten() + intercept\n",
    "        \n",
    "        # 计算误差\n",
    "        errors = y_pred - y.flatten()\n",
    "        \n",
    "        # 计算梯度\n",
    "        slope_gradient = (2/n) * np.sum(errors * X.flatten())\n",
    "        intercept_gradient = (2/n) * np.sum(errors)\n",
    "        \n",
    "        # 更新参数\n",
    "        slope = slope - learning_rate * slope_gradient\n",
    "        intercept = intercept - learning_rate * intercept_gradient\n",
    "        \n",
    "        # 记录历史\n",
    "        history['slope'].append(slope)\n",
    "        history['intercept'].append(intercept)\n",
    "        history['loss'].append(np.mean(errors ** 2))\n",
    "    \n",
    "    return slope, intercept, history\n",
    "\n",
    "# 使用梯度下降求解\n",
    "slope_gd, intercept_gd, history = gradient_descent(X, y, learning_rate=0.1, n_iterations=500)\n",
    "print(f\"梯度下降结果: y = {slope_gd:.4f}x + {intercept_gd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 可视化梯度下降过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss 曲线\n",
    "axes[0].plot(history['loss'])\n",
    "axes[0].set_xlabel('迭代次数')\n",
    "axes[0].set_ylabel('MSE Loss')\n",
    "axes[0].set_title('损失函数下降过程')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 参数变化\n",
    "axes[1].plot(history['slope'], label='斜率 (slope)', linewidth=2)\n",
    "axes[1].plot(history['intercept'], label='截距 (intercept)', linewidth=2)\n",
    "axes[1].set_xlabel('迭代次数')\n",
    "axes[1].set_ylabel('参数值')\n",
    "axes[1].set_title('参数收敛过程')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 对比结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制所有拟合结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(X, y, alpha=0.5, label='数据点')\n",
    "\n",
    "# 闭式解拟合线\n",
    "y_pred_cf = slope_cf * X + intercept_cf\n",
    "plt.plot(X, y_pred_cf, 'r-', linewidth=2, label=f'闭式解: y={slope_cf:.2f}x+{intercept_cf:.2f}')\n",
    "\n",
    "# 梯度下降拟合线\n",
    "y_pred_gd = slope_gd * X + intercept_gd\n",
    "plt.plot(X, y_pred_gd, 'b--', linewidth=2, label=f'梯度下降: y={slope_gd:.2f}x+{intercept_gd:.2f}')\n",
    "\n",
    "# 真实线\n",
    "X_range = np.array([[0], [2]])\n",
    "y_true = true_slope * X_range + true_intercept\n",
    "plt.plot(X_range, y_true, 'g:', linewidth=2, label=f'真实: y={true_slope}x+{true_intercept}')\n",
    "\n",
    "plt.xlabel('X (特征)')\n",
    "plt.ylabel('y (目标)')\n",
    "plt.title('线性回归拟合结果对比')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 计算 MSE\n",
    "mse_cf = mean_squared_error(y, y_pred_cf)\n",
    "mse_gd = mean_squared_error(y, y_pred_gd)\n",
    "print(f\"闭式解 MSE: {mse_cf:.6f}\")\n",
    "print(f\"梯度下降 MSE: {mse_gd:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用 scikit-learn\n",
    "\n",
    "在实际项目中，我们通常使用 scikit-learn 库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建并训练模型\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# 获取参数\n",
    "print(f\"scikit-learn 结果:\")\n",
    "print(f\"  斜率 (coef_): {model.coef_[0][0]:.6f}\")\n",
    "print(f\"  截距 (intercept_): {model.intercept_[0]:.6f}\")\n",
    "print(f\"  R² 得分: {model.score(X, y):.6f}\")\n",
    "\n",
    "# 预测\n",
    "y_pred_sk = model.predict(X)\n",
    "\n",
    "print(f\"\\nMSE: {mean_squared_error(y, y_pred_sk):.6f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y, y_pred_sk)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 练习：真实数据集\n",
    "\n",
    "试试在真实数据集上应用线性回归："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载波士顿房价数据集（示例）\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# 获取数据\n",
    "housing = fetch_california_housing()\n",
    "X_housing = housing.data[:, [0]]  # 只使用第一个特征\n",
    "y_housing = housing.target\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_housing, y_housing, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "model_housing = LinearRegression()\n",
    "model_housing.fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "# 评估\n",
    "y_pred_test = model_housing.predict(X_test.reshape(-1, 1))\n",
    "print(f\"R² 得分: {model_housing.score(X_test.reshape(-1, 1), y_test):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_test):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
